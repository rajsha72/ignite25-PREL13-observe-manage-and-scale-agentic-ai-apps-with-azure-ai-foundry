{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51f9f3f",
   "metadata": {},
   "source": [
    "# Deploy Finetuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab3189f",
   "metadata": {},
   "source": [
    "This notebook deploys a fine-tuned model to Azure AI using the Azure SDK. You can use this to deploy any completed fine-tuning job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301cd122",
   "metadata": {},
   "source": [
    "### 1. Check Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0065865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All required environment variables are set!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check required environment variables\n",
    "required_vars = [\n",
    "    \"AZURE_OPENAI_API_KEY\",\n",
    "    \"AZURE_OPENAI_ENDPOINT\",\n",
    "    \"AZURE_SUBSCRIPTION_ID\",\n",
    "    \"AZURE_RESOURCE_GROUP\",\n",
    "    \"AZURE_AI_FOUNDRY_NAME\"\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"‚ùå Missing environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"\\nPlease set these variables before continuing.\")\n",
    "else:\n",
    "    print(\"‚úÖ All required environment variables are set!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9769d3",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Create Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76dbee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure OpenAI client created successfully!\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2025-02-01-preview\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Azure OpenAI client created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c5165",
   "metadata": {},
   "source": [
    "\n",
    "### 3. List Available Fine-Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef96b54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 successful fine-tuning job(s):\n",
      "\n",
      "1. Job ID: ftjob-bcf37c4d7a8947c8b281a2b3e6a1ed73\n",
      "   Model: gpt-4o-2024-08-06.ft-bcf37c4d7a8947c8b281a2b3e6a1ed73\n",
      "   Created: 1762422994\n",
      "   Status: succeeded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all fine-tuning jobs\n",
    "jobs_response = client.fine_tuning.jobs.list()\n",
    "\n",
    "# Filter for succeeded jobs\n",
    "succeeded_jobs = [job for job in jobs_response.data if job.status == \"succeeded\"]\n",
    "\n",
    "if not succeeded_jobs:\n",
    "    print(\"‚ùå No successful fine-tuning jobs found.\")\n",
    "    print(\"\\nPlease complete a fine-tuning job first using 31-basic-finetuning.ipynb\")\n",
    "else:\n",
    "    print(f\"‚úÖ Found {len(succeeded_jobs)} successful fine-tuning job(s):\\n\")\n",
    "    for i, job in enumerate(succeeded_jobs, 1):\n",
    "        print(f\"{i}. Job ID: {job.id}\")\n",
    "        print(f\"   Model: {job.fine_tuned_model}\")\n",
    "        print(f\"   Created: {job.created_at}\")\n",
    "        print(f\"   Status: {job.status}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a565df",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Select Model to Deploy\n",
    "\n",
    "Enter a job ID from the list above  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3382eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a job ID (get the model name from the job)\n",
    "job_id = \"input your finetuning job ID here\"  # Replace with your job ID from the list above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afff8388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Selected model: gpt-4o-2024-08-06.ft-bcf37c4d7a8947c8b281a2b3e6a1ed73\n",
      "   From job: ftjob-bcf37c4d7a8947c8b281a2b3e6a1ed73\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Retrieve the job to get the fine-tuned model name\n",
    "job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model = job.fine_tuned_model\n",
    "\n",
    "print(f\"‚úÖ Selected model: {fine_tuned_model}\")\n",
    "print(f\"   From job: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38eafbd",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Configure Deployment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e7b00a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Deployment Configuration:\n",
      "   Name: 60-zava-finetuned-1762434734\n",
      "   Model: gpt-4o-2024-08-06.ft-bcf37c4d7a8947c8b281a2b3e6a1ed73\n",
      "   SKU: Standard\n",
      "   Capacity: 250\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Generate unique deployment name\n",
    "timestamp = int(time.time())\n",
    "DEPLOYMENT_NAME = f\"60-zava-finetuned-{timestamp}\"\n",
    "\n",
    "# Configure deployment settings\n",
    "DEPLOYMENT = {\n",
    "    \"properties\": {\n",
    "        \"model\": { \n",
    "            \"format\": \"OpenAI\", \n",
    "            \"name\": fine_tuned_model, \n",
    "            \"version\": \"1\" \n",
    "        },\n",
    "    },\n",
    "    \"sku\": { \n",
    "        \"capacity\": 250,  # Adjust based on your needs (e.g., 250 for DeveloperTier)\n",
    "        \"name\": \"Standard\"  # Options: \"DeveloperTier\", \"Standard\", \"GlobalStandard\"\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"üìã Deployment Configuration:\")\n",
    "print(f\"   Name: {DEPLOYMENT_NAME}\")\n",
    "print(f\"   Model: {fine_tuned_model}\")\n",
    "print(f\"   SKU: {DEPLOYMENT['sku']['name']}\")\n",
    "print(f\"   Capacity: {DEPLOYMENT['sku']['capacity']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac98748",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Create Azure Management Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb27911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Azure Management client created successfully!\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.cognitiveservices import CognitiveServicesManagementClient\n",
    "\n",
    "# Create management client for Azure Cognitive Services\n",
    "cogsvc_client = CognitiveServicesManagementClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    subscription_id=os.environ.get(\"AZURE_SUBSCRIPTION_ID\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Azure Management client created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da29cf8",
   "metadata": {},
   "source": [
    "\n",
    "### 7. Deploy the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21349089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting deployment of 60-zava-finetuned-1762434734...\n",
      "\n",
      "‚úÖ Deployment request submitted!\n",
      "\n",
      "‚è≥ Deployment is now provisioning...\n",
      "   This typically takes 3-5 minutes for small models\n"
     ]
    }
   ],
   "source": [
    "# Submit deployment request\n",
    "print(f\"üöÄ Starting deployment of {DEPLOYMENT_NAME}...\\n\")\n",
    "\n",
    "deployment = cogsvc_client.deployments.begin_create_or_update(\n",
    "    resource_group_name=os.environ.get(\"AZURE_RESOURCE_GROUP\"),\n",
    "    account_name=os.environ.get(\"AZURE_AI_FOUNDRY_NAME\"),\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    deployment=DEPLOYMENT,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Deployment request submitted!\")\n",
    "print(f\"\\n‚è≥ Deployment is now provisioning...\")\n",
    "print(f\"   This typically takes 3-5 minutes for small models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff190287",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Wait for Deployment to Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4382435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ≥Ô∏è  Provisioning 60-zava-finetuned-1762434734\n",
      "üìä Status: Succeeded\n",
      "‚è±Ô∏è  Elapsed time: 10 minutes 35 seconds\n",
      "\n",
      "üéâ Deployment completed successfully!\n",
      "‚è±Ô∏è  Total time: 10 minutes 35 seconds\n",
      "\n",
      "üìù Deployment Details:\n",
      "   Name: 60-zava-finetuned-1762434734\n",
      "   Model: gpt-4o-2024-08-06.ft-bcf37c4d7a8947c8b281a2b3e6a1ed73\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "status = deployment.status()\n",
    "\n",
    "while status not in [\"Succeeded\", \"Failed\"]:\n",
    "    deployment.wait(5)\n",
    "    status = deployment.status()\n",
    "    elapsed_min = int((time.time() - start_time) // 60)\n",
    "    elapsed_sec = int((time.time() - start_time) % 60)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(f\"üõ≥Ô∏è  Provisioning {DEPLOYMENT_NAME}\")\n",
    "    print(f\"üìä Status: {status}\")\n",
    "    print(f\"‚è±Ô∏è  Elapsed time: {elapsed_min} minutes {elapsed_sec} seconds\")\n",
    "\n",
    "# Final status\n",
    "elapsed_min = int((time.time() - start_time) // 60)\n",
    "elapsed_sec = int((time.time() - start_time) % 60)\n",
    "\n",
    "if status == \"Succeeded\":\n",
    "    print(f\"\\nüéâ Deployment completed successfully!\")\n",
    "    print(f\"‚è±Ô∏è  Total time: {elapsed_min} minutes {elapsed_sec} seconds\")\n",
    "    print(f\"\\nüìù Deployment Details:\")\n",
    "    print(f\"   Name: {DEPLOYMENT_NAME}\")\n",
    "    print(f\"   Model: {fine_tuned_model}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Deployment failed with status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accfc92a",
   "metadata": {},
   "source": [
    "\n",
    "### 9. Test the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7be00154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1/2: Testing deployed model with prompt:\n",
      "   'Can I use extension poles with your roller frames?'\n",
      "\n",
      "Response from 60-zava-finetuned-1762434734:\n",
      "üéØ Sure can! Telescopic Paint Pole at $17 is compatible with all Roller Frame models. How high are you planning to reach?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test 2/2: Testing deployed model with prompt:\n",
      "   'Do you have natural bristle brushes?'\n",
      "\n",
      "Response from 60-zava-finetuned-1762434734:\n",
      "üéØ Sure can! Telescopic Paint Pole at $17 is compatible with all Roller Frame models. How high are you planning to reach?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Test 2/2: Testing deployed model with prompt:\n",
      "   'Do you have natural bristle brushes?'\n",
      "\n",
      "Response from 60-zava-finetuned-1762434734:\n",
      "üíº Natural Bristle Set is $33, with 1\", 2\", and 3\" sizes. Great for oil-based products! üòäüë©‚Äçüé® Prepping surface tips too?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Response from 60-zava-finetuned-1762434734:\n",
      "üíº Natural Bristle Set is $33, with 1\", 2\", and 3\" sizes. Great for oil-based products! üòäüë©‚Äçüé® Prepping surface tips too?\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the deployed model with multiple sample prompts\n",
    "test_prompts = [\n",
    "    \"Can I use extension poles with your roller frames?\",\n",
    "    \"Do you have natural bristle brushes?\"\n",
    "]\n",
    "\n",
    "for i, test_prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"Test {i}/{len(test_prompts)}: Testing deployed model with prompt:\")\n",
    "    print(f\"   '{test_prompt}'\\n\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=DEPLOYMENT_NAME,  # Use the deployment name\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are Cora, a polite, factual and helpful assistant for Zava, a DIY hardware store.\"},\n",
    "            {\"role\": \"user\", \"content\": test_prompt}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    print(f\"Response from {DEPLOYMENT_NAME}:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586cd4ff",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "In both the examples above we can note that the response now accurately follows our Zava guidelines for \"polite, factual and helpful\"\n",
    "- Every response starts with an emoji\n",
    "- The first sentence is always an acknowledgement of the user (\"polite\")\n",
    "- The next sentence is always an informative segment (\"factual\")\n",
    "- The final senteance is always an offer to follow up (\"helpful\")\n",
    "\n",
    "And note that we have the succinct responses we were looking for _without adding few-shot examples_, making the prompts shorter and thus saving both token costs and processing latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757601c1",
   "metadata": {},
   "source": [
    "---\n",
    "### Teardown\n",
    "\n",
    "Once you are done with this lab, don't forget to tear down the infrastructure. The developer tier model will be torn down automatically (after 24 hours?) but it is better to proactively delete the resource group and release all model quota."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
