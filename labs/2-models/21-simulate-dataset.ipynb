{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Simulate Datasets for Evaluation\n",
    "\n",
    "Welcome! This notebook will walk you through generating synthetic datasets using Azure AI Search and the Azure AI Evaluation Simulator.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to configure the Azure AI Evaluation Simulator\n",
    "- How to connect to Azure AI Search to retrieve content\n",
    "- How to create a RAG application callback\n",
    "- How to generate synthetic query-response pairs\n",
    "- How to save and review the generated dataset\n",
    "\n",
    "Let's get started! ðŸš€\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Verify Environment Variables\n",
    "\n",
    "The following environment variables should already be configured in your `.env` file from the earlier setup steps:\n",
    "\n",
    "- **AZURE_OPENAI_API_KEY**: Your Azure OpenAI API key\n",
    "- **AZURE_OPENAI_ENDPOINT**: Your Azure OpenAI service endpoint\n",
    "- **AZURE_OPENAI_API_VERSION**: The API version to use\n",
    "- **AZURE_OPENAI_DEPLOYMENT**: The name of your deployed chat model\n",
    "- **AZURE_SEARCH_ENDPOINT**: Your Azure AI Search service endpoint\n",
    "- **AZURE_SEARCH_API_KEY**: Your Azure AI Search API key\n",
    "- **AZURE_SEARCH_INDEX_NAME**: The name of your search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All environment variables configured!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify all required Azure service credentials are available\n",
    "required_vars = [\n",
    "    \"AZURE_OPENAI_API_KEY\",\n",
    "    \"AZURE_OPENAI_ENDPOINT\", \n",
    "    \"AZURE_OPENAI_API_VERSION\",\n",
    "    \"AZURE_OPENAI_DEPLOYMENT\",\n",
    "    \"AZURE_SEARCH_ENDPOINT\",\n",
    "    \"AZURE_SEARCH_API_KEY\",\n",
    "    \"AZURE_SEARCH_INDEX_NAME\"\n",
    "]\n",
    "\n",
    "missing_vars = [var for var in required_vars if not os.environ.get(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    raise EnvironmentError(f\"âŒ Missing environment variables: {', '.join(missing_vars)}\")\n",
    "\n",
    "print(\"âœ… All environment variables configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Azure AI Search configured with index: zava-products\n"
     ]
    }
   ],
   "source": [
    "# Initialize Azure AI Search connection parameters\n",
    "search_endpoint = os.environ.get(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_api_key = os.environ.get(\"AZURE_SEARCH_API_KEY\") \n",
    "search_index_name = os.environ.get(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "\n",
    "print(f\"âœ… Azure AI Search configured with index: {search_index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Azure OpenAI Model\n",
    "\n",
    "Now let's create the model configuration that the simulator will use to generate synthetic queries and responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model configuration created for: gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "\n",
    "# Create model configuration using environment variables\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"), \n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")\n",
    "\n",
    "print(f\"âœ… Model configuration created for: {model_config['azure_deployment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize the Simulator\n",
    "\n",
    "Let's create the Azure AI Evaluation Simulator instance using the model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class Simulator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Simulator initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# 4. Initialize the Azure AI Evaluation Simulator\n",
    "from azure.ai.evaluation.simulator import Simulator\n",
    "\n",
    "# Create simulator instance with the configured model\n",
    "simulator = Simulator(model_config=model_config)\n",
    "print(\"ðŸ“Š Simulator initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4: Define Search Function\n",
    "\n",
    "This function will search the Azure AI Search index for relevant content based on queries. It will be used by the RAG application callback to retrieve context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Define function to search Azure AI Search index and retrieve content\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def search_index_for_content(query: str, top_k: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Search the Azure AI Search index for relevant content based on a query.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search query to find relevant content\n",
    "        top_k (int): Number of top results to retrieve (default: 5)\n",
    "    \n",
    "    Returns:\n",
    "        str: Combined content from search results, truncated to 1000 characters\n",
    "    \"\"\"\n",
    "    # Construct the search API endpoint\n",
    "    search_url = f\"{search_endpoint}/indexes/{search_index_name}/docs/search?api-version=2023-11-01\"\n",
    "    \n",
    "    # Set up request headers with API key authentication\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": search_api_key\n",
    "    }\n",
    "    \n",
    "    # Define the search query payload\n",
    "    search_payload = {\n",
    "        \"search\": query,\n",
    "        \"top\": top_k,\n",
    "        \"select\": \"content,title\"  # Updated to match available fields\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Execute the search request\n",
    "        response = requests.post(url=search_url, headers=headers, json=search_payload)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP error codes\n",
    "        \n",
    "        # Parse the search results\n",
    "        search_results = response.json()\n",
    "        combined_content = \"\"\n",
    "        \n",
    "        # Extract and combine content from search results\n",
    "        for result in search_results.get(\"value\", []):\n",
    "            # Prioritize 'content' field, fall back to 'title'\n",
    "            content = result.get(\"content\") or result.get(\"title\", \"\")\n",
    "            if content:\n",
    "                combined_content += content + \" \"\n",
    "        \n",
    "        # Limit content length to prevent token limits and improve performance\n",
    "        return combined_content[:1000].strip()\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ Error searching index: {e}\")\n",
    "        return f\"Error retrieving content for query: {query}\"\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"âŒ Error parsing search response: {e}\")\n",
    "        return f\"Error processing search results for query: {query}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test the Search Function\n",
    "\n",
    "Let's verify that the search function works correctly by testing it with a sample query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Search test successful!\n",
      "ðŸ“„ Retrieved response: Durable eggshell finish paint with subtle sheen, ideal for living rooms and bedrooms with easy cleanup. Disposable plastic liners that fit standard paint trays for quick cleanup and color changes. Environmentally friendly zero-VOC paint for healthy indoor air quality in all living spaces. Premium acrylic exterior paint with fade resistance and superior adhesion for long-lasting protection. Washable semi-gloss interior paint for kitchens, bathrooms, and trim work with moisture resistance. for query: 'eggshell paint'\n"
     ]
    }
   ],
   "source": [
    "# Test the search function with a sample query\n",
    "test_query = \"eggshell paint\"\n",
    "retrieved_content = search_index_for_content(test_query)\n",
    "\n",
    "print(f\"âœ… Search test successful!\")\n",
    "print(f\"ðŸ“„ Retrieved response: {retrieved_content} for query: '{test_query}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create RAG Application Callback\n",
    "\n",
    "This callback function simulates a RAG (Retrieval-Augmented Generation) application that:\n",
    "- Extracts user queries from messages\n",
    "- Searches the index for relevant content\n",
    "- Generates responses using Azure OpenAI\n",
    "- Returns formatted responses for the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Define the application callback function for the simulator\n",
    "from typing import Dict, Any, Optional\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "async def rag_application_callback(\n",
    "    messages: Dict,\n",
    "    stream: bool = False,\n",
    "    session_state: Any = None,\n",
    "    context: Optional[Dict[str, Any]] = None,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Callback function that simulates a RAG (Retrieval-Augmented Generation) application.\n",
    "    \n",
    "    This function:\n",
    "    1. Extracts the user query from the message\n",
    "    2. Searches the Azure AI Search index for relevant content\n",
    "    3. Uses Azure OpenAI to generate a response based on the retrieved content\n",
    "    4. Returns the response in the expected format\n",
    "    \n",
    "    Args:\n",
    "        messages (Dict): Message history containing user queries\n",
    "        stream (bool): Whether to stream the response (not used in this implementation)\n",
    "        session_state (Any): Session state information\n",
    "        context (Optional[Dict[str, Any]]): Additional context information\n",
    "    \n",
    "    Returns:\n",
    "        Dict: Response containing the generated message and metadata\n",
    "    \"\"\"\n",
    "    # Extract the user's query from the latest message\n",
    "    messages_list = messages[\"messages\"]\n",
    "    user_query = messages_list[-1][\"content\"]\n",
    "    \n",
    "    # Initialize Azure OpenAI client\n",
    "    openai_client = AzureOpenAI(\n",
    "        azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "    \n",
    "    # Retrieve relevant content from the search index\n",
    "    retrieved_context = search_index_for_content(user_query)\n",
    "    \n",
    "    # Create a system prompt that instructs the model to use the retrieved context\n",
    "    system_prompt = \"\"\"You are a polite and helpful assistant that answers questions based on the provided context. \n",
    "Use the context information to provide accurate and relevant responses. If the context doesn't contain \n",
    "enough information to answer the question, say so politely. If the context mentions a product by name, reference it in the response.\"\"\"\n",
    "    \n",
    "    # Generate response using Azure OpenAI\n",
    "    try:\n",
    "        completion = openai_client.chat.completions.create(\n",
    "            model=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Context: {retrieved_context}\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Question: {user_query}\"}\n",
    "            ],\n",
    "            max_tokens=500,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        \n",
    "        # Extract the generated response\n",
    "        ai_response = completion.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        ai_response = f\"Sorry, I encountered an error while generating a response: {str(e)}\"\n",
    "    \n",
    "    # Format the response according to the expected structure\n",
    "    response_message = {\n",
    "        \"content\": ai_response,\n",
    "        \"role\": \"assistant\",\n",
    "        \"context\": retrieved_context,\n",
    "    }\n",
    "    \n",
    "    # Add the response to the message history\n",
    "    messages[\"messages\"].append(response_message)\n",
    "    \n",
    "    # Return the complete response structure\n",
    "    return {\n",
    "        \"messages\": messages[\"messages\"], \n",
    "        \"stream\": stream, \n",
    "        \"session_state\": session_state, \n",
    "        \"context\": retrieved_context\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Synthetic Dataset\n",
    "\n",
    "Now we'll use the simulator to generate synthetic query-response pairs based on content from the search index. This will create 5 query-response pairs for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ready to simulate with 492 characters of content\n"
     ]
    }
   ],
   "source": [
    "# Verify the retrieved content is ready for simulation\n",
    "if not retrieved_content:\n",
    "    raise ValueError(\"No content retrieved from search. Please run Step 5 again with a valid query.\")\n",
    "\n",
    "print(f\"âœ… Ready to simulate with {len(retrieved_content)} characters of content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.12/site-packages/azure/ai/evaluation/simulator/_simulator.py:157: UserWarning: You have specified 'num_queries' > len('tasks') (10 > 0). All tasks will be used for generation and the remaining 10 lines will be simulated in task-free mode\n",
      "  warnings.warn(\n",
      "Generating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.31s/message]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generated 10 synthetic query-response pairs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Run the simulator to generate synthetic data\n",
    "# The simulator needs a list of query-response dictionaries or plain text\n",
    "synthetic_outputs = await simulator(\n",
    "    target=rag_application_callback,\n",
    "    text=retrieved_content,\n",
    "    num_queries=10,\n",
    "    max_conversation_turns=1,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Generated {len(synthetic_outputs)} synthetic query-response pairs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save the Dataset to File\n",
    "\n",
    "Let's save the generated dataset to a JSONL file for use in evaluation workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset saved to: /workspaces/ignite25-PDY123-learn-how-to-observe-manage-and-scale-agentic-ai-apps-using-azure/labs/2-models/21-simulate-datasets.jsonl\n"
     ]
    }
   ],
   "source": [
    "output_file = Path(\"21-simulate-datasets.jsonl\")\n",
    "\n",
    "# Write each output as a JSON line to the file\n",
    "with output_file.open(\"w\") as f:\n",
    "    for output in synthetic_outputs:\n",
    "        f.write(output.to_eval_qr_json_lines())\n",
    "\n",
    "print(f\"âœ… Dataset saved to: {output_file.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Preview the Dataset\n",
    "\n",
    "Let's load and display a preview of the generated dataset to verify its structure and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded: 10 rows, 3 columns\n",
      "ðŸ“‹ Columns: ['query', 'response', 'context']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What type of finish does the durable eggshell ...</td>\n",
       "      <td>The durable eggshell finish paint has a subtle...</td>\n",
       "      <td>Durable eggshell finish paint with subtle shee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which rooms are recommended for the durable eg...</td>\n",
       "      <td>The durable eggshell finish paint with subtle ...</td>\n",
       "      <td>Durable eggshell finish paint with subtle shee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What feature makes the durable eggshell finish...</td>\n",
       "      <td>The durable eggshell finish paint is easy to m...</td>\n",
       "      <td>Durable eggshell finish paint with subtle shee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What product fits standard paint trays for qui...</td>\n",
       "      <td>The product that fits standard paint trays for...</td>\n",
       "      <td>Disposable plastic liners that fit standard pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the main environmental benefit of the ...</td>\n",
       "      <td>The main environmental benefit of the zero-VOC...</td>\n",
       "      <td>Environmentally friendly zero-VOC paint for he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What type of paint is recommended for all livi...</td>\n",
       "      <td>The environmentally friendly zero-VOC paint is...</td>\n",
       "      <td>Environmentally friendly zero-VOC paint for he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Which paint is described as premium acrylic ex...</td>\n",
       "      <td>The paint described as premium acrylic exterio...</td>\n",
       "      <td>Premium acrylic exterior paint with fade resis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the two main features of the premium ...</td>\n",
       "      <td>The two main features of the premium acrylic e...</td>\n",
       "      <td>Premium acrylic exterior paint with fade resis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Which paint is recommended for kitchens, bathr...</td>\n",
       "      <td>The washable semi-gloss interior paint is reco...</td>\n",
       "      <td>Washable semi-gloss interior paint for kitchen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the key feature of the washable semi-g...</td>\n",
       "      <td>The key feature of the washable semi-gloss int...</td>\n",
       "      <td>Washable semi-gloss interior paint for kitchen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  What type of finish does the durable eggshell ...   \n",
       "1  Which rooms are recommended for the durable eg...   \n",
       "2  What feature makes the durable eggshell finish...   \n",
       "3  What product fits standard paint trays for qui...   \n",
       "4  What is the main environmental benefit of the ...   \n",
       "5  What type of paint is recommended for all livi...   \n",
       "6  Which paint is described as premium acrylic ex...   \n",
       "7  What are the two main features of the premium ...   \n",
       "8  Which paint is recommended for kitchens, bathr...   \n",
       "9  What is the key feature of the washable semi-g...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The durable eggshell finish paint has a subtle...   \n",
       "1  The durable eggshell finish paint with subtle ...   \n",
       "2  The durable eggshell finish paint is easy to m...   \n",
       "3  The product that fits standard paint trays for...   \n",
       "4  The main environmental benefit of the zero-VOC...   \n",
       "5  The environmentally friendly zero-VOC paint is...   \n",
       "6  The paint described as premium acrylic exterio...   \n",
       "7  The two main features of the premium acrylic e...   \n",
       "8  The washable semi-gloss interior paint is reco...   \n",
       "9  The key feature of the washable semi-gloss int...   \n",
       "\n",
       "                                             context  \n",
       "0  Durable eggshell finish paint with subtle shee...  \n",
       "1  Durable eggshell finish paint with subtle shee...  \n",
       "2  Durable eggshell finish paint with subtle shee...  \n",
       "3  Disposable plastic liners that fit standard pa...  \n",
       "4  Environmentally friendly zero-VOC paint for he...  \n",
       "5  Environmentally friendly zero-VOC paint for he...  \n",
       "6  Premium acrylic exterior paint with fade resis...  \n",
       "7  Premium acrylic exterior paint with fade resis...  \n",
       "8  Washable semi-gloss interior paint for kitchen...  \n",
       "9  Washable semi-gloss interior paint for kitchen...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and display the dataset\n",
    "dataset_df = pd.read_json(output_file, lines=True)\n",
    "\n",
    "print(f\"âœ… Dataset loaded: {dataset_df.shape[0]} rows, {dataset_df.shape[1]} columns\")\n",
    "print(f\"ðŸ“‹ Columns: {list(dataset_df.columns)}\")\n",
    "print()\n",
    "\n",
    "# Show first few records\n",
    "dataset_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Review the Dataset File\n",
    "\n",
    "Open the `21-simulate-datasets.jsonl` file in VS Code to examine the generated query-response-context triples and verify the data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "You've successfully generated a synthetic evaluation dataset! You can now use this dataset to:\n",
    "- Evaluate your RAG application's retrieval quality\n",
    "- Test and fine-tune your system prompts\n",
    "- Benchmark your application's performance\n",
    "- Create test cases for development\n",
    "\n",
    "Great work! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
